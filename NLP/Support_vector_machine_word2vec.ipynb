{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import operator\n",
    "import nltk.data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data_raw.json\") as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New data set. Only negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"negative.json\") as n:\n",
    "    negative_data = json.loads(n.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160955\n",
      "4647\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(negative_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.extend(negative_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From PyMystem import russian stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "stopWords = set(stopwords.words(\"russian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badwords = [\n",
    "u'я', u'а', u'да', u'но', u'тебе', u'мне', u'ты', u'и', u'у', u'на', u'ща', u'ага',\n",
    "u'так', u'там', u'какие', u'который', u'какая', u'туда', u'давай', u'короче', u'кажется', u'вообще',\n",
    "u'ну', u'не', u'чет', u'неа', u'свои', u'наше', u'хотя', u'такое', u'например', u'кароч', u'как-то',\n",
    "u'нам', u'хм', u'всем', u'нет', u'да', u'оно', u'своем', u'про', u'вы', u'м', u'тд',\n",
    "u'вся', u'кто-то', u'что-то', u'вам', u'это', u'эта', u'эти', u'этот', u'прям', u'либо', u'как', u'мы',\n",
    "u'просто', u'блин', u'очень', u'самые', u'твоем', u'ваша', u'кстати', u'вроде', u'типа', u'пока', u'ок',u'в'\n",
    ",u'б',u'г',u'д',u'е',u'ж',u'з',u'й',u'к',u'л',u'ф',u'н',u'о',u'п',u'р',u'с',u'т',u'ч',u'ц',u'ч',u'ш',u'щ',u'ь'\n",
    ",u'ъ',u'ы',u'э','ю']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in badwords:\n",
    "    stopWords.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemma(data):\n",
    "    lemmas = m.lemmatize(data)\n",
    "    return ''.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove from text stop words but we don't remove negations \"не\" and \"ни\" for future concatination it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_remove(data, negation=False):\n",
    "    for word in stopWords:\n",
    "        if((word == u'не' or word == u\"ни\") and negation == False):\n",
    "            continue\n",
    "        if (word in data):\n",
    "            for item in range(data.count(word)):\n",
    "                data.remove(word)\n",
    "    return data            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    cleaned_data = re.sub(\"[^а-яА-ЯЁё]\",\" \", data) # leave only russian text\n",
    "    cleaned_data = lemma(cleaned_data)\n",
    "    cleaned_data = cleaned_data.lower().split()\n",
    "    cleaned_data = stop_remove(cleaned_data)\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatinate negations with words like \"не хотеть\" to \"нехотеть\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat(data):\n",
    "    check = False\n",
    "    for i in range (0, len(data)-1):\n",
    "        if(data[i] == u'не' or data[i] == u'ни'):\n",
    "            data[i+1]=(data[i]+data[i+1])\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral 87341\n",
      "Positive 60761\n",
      "Negative 17500\n",
      "All sentiment 165602\n"
     ]
    }
   ],
   "source": [
    "neutral = 0\n",
    "positive = 0\n",
    "negative = 0\n",
    "\n",
    "for item in data:\n",
    "    if item['manual_sentiment'] == 'neutral':\n",
    "        neutral+=1\n",
    "    elif item['manual_sentiment'] == 'positive':\n",
    "        positive+=1\n",
    "    else:\n",
    "        negative+=1\n",
    "        \n",
    "print(\"Neutral\", neutral)\n",
    "print(\"Positive\", positive)\n",
    "print(\"Negative\", negative)\n",
    "print(\"All sentiment\", neutral+positive+negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleansing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,len(data)):\n",
    "    data[i][\"text\"] = cleaning(data[i][\"text\"])\n",
    "    data[i][\"text\"] = concat(data[i][\"text\"])\n",
    "    data[i][\"text\"] = stop_remove(data[i][\"text\"],True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicated posts. The reason that I remove all duplicates after cleaning is some cases when one text is the same like another but with few stopwords added. So I decided to clean and then remove duplicates. After this step I solved this problem with duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates 47815\n",
      "Duplicates with different sentiment 20668\n"
     ]
    }
   ],
   "source": [
    "# deleting duplicates \n",
    "new_list = list()\n",
    "cnt = 0\n",
    "for i in data:\n",
    "    if (i not in new_list):\n",
    "        new_list.append(i)\n",
    "    else:\n",
    "        cnt+=1\n",
    "print (\"Duplicates\",cnt)\n",
    "\n",
    "#deleting duplicates with the same text but with different sentiment\n",
    "new_list2 = list()\n",
    "cnt = 0\n",
    "for i in new_list:\n",
    "    check = False\n",
    "    for j in new_list:\n",
    "        if (i[\"text\"] == j[\"text\"]) and ( i[\"manual_sentiment\"] != j[\"manual_sentiment\"] ):\n",
    "            check = True\n",
    "            cnt+=1\n",
    "    if check == False:\n",
    "        new_list2.append(i)\n",
    "print(\"Duplicates with different sentiment\",cnt)\n",
    "new_list.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral 54348\n",
      "Positive 37136\n",
      "Negative 10583\n",
      "All sentiment 102067\n"
     ]
    }
   ],
   "source": [
    "# divide our data into text and sentiment (where positive = 1, neutral = 0, negative = -1)\n",
    "text = []\n",
    "sentiment = []\n",
    "neutral = 0\n",
    "positive = 0\n",
    "negative = 0\n",
    "\n",
    "for item in new_list2:\n",
    "    text.append(item['text'])\n",
    "    if item['manual_sentiment'] == 'neutral':\n",
    "        sentiment.append(0)\n",
    "        neutral+=1\n",
    "    elif item['manual_sentiment'] == 'positive':\n",
    "        sentiment.append(1)\n",
    "        positive+=1\n",
    "    else:\n",
    "        sentiment.append(-1)\n",
    "        negative+=1\n",
    "        \n",
    "print(\"Neutral\", neutral)\n",
    "print(\"Positive\", positive)\n",
    "print(\"Negative\", negative)\n",
    "print(\"All sentiment\", neutral+positive+negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload our cleaned data to json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open (\"data_prepared.json\", \"w\", encoding='utf-8') as outfile:\n",
    "    outfile.write('[')\n",
    "    for i in range(0, len(new_list2)):\n",
    "        json.dump(new_list2[i], outfile, ensure_ascii=False)\n",
    "        if i+1 < len(new_list2):\n",
    "            outfile.write(',')\n",
    "        outfile.write('\\n')    \n",
    "    outfile.write(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Vectorization. 2.1 Bag of words model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = dict()\n",
    "#check appearence of the text then build dictionary\n",
    "for sentence in new_list2:\n",
    "    for word in sentence[\"text\"]:\n",
    "        if word not in word_index:\n",
    "            word_index[word] = 0\n",
    "        else:\n",
    "            word_index[word]+=1\n",
    "#sort our dictionary in descending order by its appearence             \n",
    "sorted_words = sorted(word_index.items(), key=operator.itemgetter(1), reverse=True)        \n",
    "\n",
    "#build matrices with 5000 features(dimensions)\n",
    "matrices = np.zeros(shape=(len(new_list2),5000))\n",
    "vocabulary = dict()\n",
    "\n",
    "for i in range(5000):\n",
    "    vocabulary[sorted_words[i][0]] = i\n",
    "\n",
    "cnt = 0\n",
    "i = 0\n",
    "\n",
    "for sentence in new_list2:\n",
    "    for word in sentence[\"text\"]:\n",
    "        if word in vocabulary:\n",
    "            if matrices[i,vocabulary[word]] == 0:\n",
    "                matrices[i,vocabulary[word]] = 1\n",
    "            else:\n",
    "                matrices[i,vocabulary[word]]+=1\n",
    "        cnt+=1\n",
    "    i+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102069"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = list()\n",
    "sentiment = 0\n",
    "for i in range(len(matrices)):\n",
    "    if new_list2[i][\"manual_sentiment\"] == \"neutral\":\n",
    "        sentiment = 0\n",
    "    elif new_list2[i][\"manual_sentiment\"] == \"negative\":\n",
    "        sentiment = -1\n",
    "    else:\n",
    "        sentiment = 1  \n",
    "    result.append((matrices[i],sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.,  5.,  0., ...,  0.,  0.,  0.]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('matrices.pkl', 'wb') as f:\n",
    "    pickle.dump(result,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Vectorization. 2.2 Word2Vec algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "sentiment = []\n",
    "neutral = 0\n",
    "positive = 0\n",
    "for item in new_list2:\n",
    "    if item[\"manual_sentiment\"] == \"neutral\" and neutral < 30000:\n",
    "        text.append(item[\"text\"])\n",
    "        sentiment.append(0)\n",
    "        neutral+=1\n",
    "    elif item[\"manual_sentiment\"] == \"positive\" and positive < 25000:\n",
    "        text.append(item[\"text\"])\n",
    "        sentiment.append(1)\n",
    "        positive+=1\n",
    "    elif item[\"manual_sentiment\"] == \"negative\":\n",
    "        text.append(item[\"text\"])\n",
    "        sentiment.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 50\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(text,workers=num_workers, size=num_features,\\\n",
    "                          min_count = min_word_count,window=context, sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.init_sims(replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"SVC_word2vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec shows quite good results with word similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('алматы', 0.7707394361495972),\n",
       " ('астан', 0.7488085031509399),\n",
       " ('столица', 0.7461706399917603),\n",
       " ('столичный', 0.7252397537231445),\n",
       " ('экспо', 0.7173423171043396),\n",
       " ('универсиада', 0.6010549068450928),\n",
       " ('специализированный', 0.597379207611084),\n",
       " ('выставка', 0.5972445607185364),\n",
       " ('авиарейс', 0.5960143208503723),\n",
       " ('город', 0.5849112272262573)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('астана')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to average all of the word vectors in a given paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words,model,num_features):\n",
    "    featureVec = np.zeros((num_features,), dtype='float32')\n",
    "    n = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n+=1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    featureVec = np.divide(featureVec,n)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that calculates the average feature vector for each one and return a 2D numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAverageVec(posts, model,num_features):\n",
    "    cnt = 0\n",
    "    reviewFeatureVecs = np.zeros((len(posts), num_features), dtype='float32')\n",
    "    \n",
    "    for sentence in posts:\n",
    "        reviewFeatureVecs[cnt] = makeFeatureVec(sentence,model,num_features)\n",
    "        cnt+=1\n",
    "    return reviewFeatureVecs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danit/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "DataVecs = getAverageVec(text,model,num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values, because it can greatly affect to our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(DataVecs).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(DataVecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change empty values to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataVecs = np.nan_to_num(DataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(DataVecs).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Building and Investigating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Support vector classifier with bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason that I limit my training set was huge amount of neutral texts. Then I think it \"overfitted\" on neutral examples, that decreased my accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-9c7755773663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mneutral\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"neutral\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mneutral\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "neutral = 0\n",
    "positive = 0\n",
    "for i in range (len(result)):\n",
    "    if(result[i][1] == \"neutral\" and neutral < 30000):\n",
    "        X.append(result[i][0])\n",
    "        y.append(result[i][1])\n",
    "    elif(result[i][1] == \"positive\" and positive < 25000):\n",
    "        X.append(result[i][0])\n",
    "        y.append(result[i][1])\n",
    "    elif result[i][1] == \"negative\":\n",
    "        X.append(result[i][0])\n",
    "        y.append(result[i][1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC_BoW = SVC(decision_function_shape = \"ovr\", kernel='linear', gamma=0.1, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_BoW.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = SVC_BoW.predict(X_test)\n",
    "print('Accuracy:', SVC_BoW.score(X_test, y_test))\n",
    "print('Metrics:', metrics.classification_report(predicted,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model illustrated us pretty good model, but we need robust and complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Support vector classifier with Word2Vec algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65583"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(DataVecs, sentiment, test_size = 0.2, random_state = 42)\n",
    "SVC_W2V = SVC(decision_function_shape = \"ovr\", kernel='linear', gamma=0.1, C=1)\n",
    "SVC_W2V.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good results, before we had 30% of precision value on negative sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.691621559808\n",
      "Metrics              precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.51      0.71      0.60      1544\n",
      "          0       0.71      0.67      0.69      6332\n",
      "          1       0.75      0.71      0.73      5241\n",
      "\n",
      "avg / total       0.70      0.69      0.69     13117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = SVC_W2V.predict(X_test)\n",
    "print(\"Accuracy\", SVC_W2V.score(X_test,y_test))\n",
    "print(\"Metrics\", metrics.classification_report(predicted,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's brute force our parameters and train them on whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [1, 10, 100], 'kernel': ['linear']}, {'C': [1, 10, 100], 'gamma': [0.001, 0.01, 0.1], 'kernel': ['rbf']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for training on 100% samples then we upload new testing set on 4th step\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100], 'gamma': [0.001, 0.01,0.1], 'kernel': ['rbf']},\n",
    "]\n",
    "SVC_W2V = GridSearchCV(SVC(), param_grid, cv = 5)\n",
    "SVC_W2V.fit(DataVecs,sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(SVC_W2V.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC_W2V_best = SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_W2V_best.fit(DataVecs,sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We  see here much better results, by increasing precision value of negative samples from 30% to 51 %, even this is just randomly choosen parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4 Uploading new testing set and make the same cleaning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to be sure that our model is robust we uploaded new testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data_test.json\") as f:\n",
    "    test = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative 1093\n",
      "Positive 2580\n",
      "Neutral 9068\n",
      "Total 12741\n"
     ]
    }
   ],
   "source": [
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "for item in test:\n",
    "    if item[\"manual_sentiment\"] == \"neutral\":\n",
    "        neutral+=1\n",
    "    if item[\"manual_sentiment\"] == \"positive\":\n",
    "        positive+=1\n",
    "    if item[\"manual_sentiment\"] == \"negative\":\n",
    "        negative+=1 \n",
    "print(\"Negative\", negative)\n",
    "print(\"Positive\", positive)\n",
    "print(\"Neutral\", neutral)\n",
    "print(\"Total\", negative+positive+neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(test)):\n",
    "    test[i][\"text\"] = cleaning(test[i][\"text\"])\n",
    "    test[i][\"text\"] = concat(test[i][\"text\"])\n",
    "    test[i][\"text\"] = stop_remove(test[i][\"text\"],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates 4623\n",
      "Duplicates with different sentiment 1416\n"
     ]
    }
   ],
   "source": [
    "# deleting duplicates \n",
    "test_list = list()\n",
    "cnt = 0\n",
    "for i in test:\n",
    "    if (i not in test_list):\n",
    "        test_list.append(i)\n",
    "    else:\n",
    "        cnt+=1\n",
    "print (\"Duplicates\",cnt)\n",
    "\n",
    "#deleting duplicates with the same text but with different sentiment\n",
    "test_list2 = list()\n",
    "cnt = 0\n",
    "for i in test_list:\n",
    "    check = False\n",
    "    for j in test_list:\n",
    "        if (i[\"text\"] == j[\"text\"]) and ( i[\"manual_sentiment\"] != j[\"manual_sentiment\"] ):\n",
    "            check = True\n",
    "            cnt+=1\n",
    "    if check == False:\n",
    "        test_list2.append(i)\n",
    "print(\"Duplicates with different sentiment\",cnt)\n",
    "test_list.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral 5052\n",
      "Positive 1179\n",
      "Negative 513\n",
      "All sentiment 6744\n"
     ]
    }
   ],
   "source": [
    "# divide our data into text and sentiment (where positive = 1, neutral = 0, negative = -1)\n",
    "test_text = []\n",
    "test_sentiment = []\n",
    "neutral = 0\n",
    "positive = 0\n",
    "negative = 0\n",
    "\n",
    "for item in test_list2:\n",
    "    test_text.append(item['text'])\n",
    "    if item['manual_sentiment'] == 'neutral':\n",
    "        test_sentiment.append(0)\n",
    "        neutral+=1\n",
    "    elif item['manual_sentiment'] == 'positive':\n",
    "        test_sentiment.append(1)\n",
    "        positive+=1\n",
    "    else:\n",
    "        test_sentiment.append(-1)\n",
    "        negative+=1\n",
    "        \n",
    "print(\"Neutral\", neutral)\n",
    "print(\"Positive\", positive)\n",
    "print(\"Negative\", negative)\n",
    "print(\"All sentiment\", neutral+positive+negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestDataVecs = getAverageVec(test_text,model,num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.68371886121\n",
      "Metrics              precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.53      0.27      0.36       999\n",
      "          0       0.70      0.86      0.77      4109\n",
      "          1       0.68      0.49      0.57      1636\n",
      "\n",
      "avg / total       0.67      0.68      0.66      6744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = SVC_W2V_best.predict(TestDataVecs)\n",
    "print(\"Accuracy\", SVC_W2V.score(TestDataVecs,test_sentiment))\n",
    "print(\"Metrics\", metrics.classification_report(predicted,test_sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In conclusion, we see that support vector machine with word2vec model works fine, even there not so many negative samples. I need to find more training samples, especially negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
